{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Minimally Sufficient Pandas with Ted Petrou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Author of Pandas Cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Founder of Dunder Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Who knows that Pandas refers to a Python library as well as an east-Asian bear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Have you used Pandas before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Have you used Pandas in production before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Do these apply to you\n",
    "* Don't know the difference between `[], .iloc, .loc, .ix, .at, .iat`\n",
    "* Use `reset_index` frequently because you have no idea how to deal with MultiIndexes\n",
    "* Use for-loops frequently\n",
    "* Use `apply` frequently\n",
    "* Struggle with Pandas, and find yourself wishing it was easy as R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas Quiz #1\n",
    "# How do you select the food column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/sample_data.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas Quiz #2\n",
    "### How do you select the row just for Penelope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas Quiz #3\n",
    "### How would you select the food and age columns for everyone over the age of 30?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Minimally Sufficient Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* There are multiple ways to accomplish most tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Often, there is not an obvious way to do things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A small subset of the library covers nearly all of the possible tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Knowing many obscure Pandas tricks is not helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Developing a standard Pandas usage guide can be helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Pandas can be written in a very implicit way. Be as explicit as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Ask yourself whether method B gives you more functionality than method A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Pandas is difficult to use in production - striving for consistency and simplicity can make a big difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* There are an incredible amount of issues/bugs and using a minimally sufficient subset of Pandas can help avoid landing on a bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Use only bracket notation and never dot notation to select single columns\n",
    "    * Columns with spaces do not work\n",
    "    * Column names that collide with methods do not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Only use string names for columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Avoid chained indexing, especially when assigning new values to subsets of data\n",
    "    * Do not do this: `df[df['col1'] > 10]['col2'] = 10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Never use `.ix` for subset selection. It is deprecated.\n",
    "* No reason to use `.at` and `.iat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Use bracket notation instead of the `query` method to do boolean selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Use the arithmetic and comparison operators instead of their counterpart methods (`add`, `gt`, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Use DataFrame/Series methods when they exist\n",
    "    * Avoid built-in `Python` functions\n",
    "    * Avoid the `apply` method when possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Do not store complex data types in DataFrame/Series values - i.e. no lists, Series, or DataFrames within DataFrames/Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Decide on a syntax for grouping (especially when aggregating)\n",
    "    * `df.groupby(['grouping', 'columns']).agg({'aggregating column': 'aggregating func'})`\n",
    "    * `df.groupby(['grouping', 'columns'])['aggregating column'].aggregating_func()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Have a standard way of handling a multi-level Index\n",
    "    * Should you reset to single level? \n",
    "    * Should you reset and rename multi-level column indexes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Be very careful when calling `apply` on a `groupby` - this is the slowest operation in Pandas\n",
    "    * Pre-calculate anything that is independent of the group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `melt/pivot` vs `stack/unstack` - They both do the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chained Indexing\n",
    "Occurs when consecutive subset selection. If you see back to back brackets (`][`), you have done chained indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['color', 'food', 'state']][['color', 'food']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a single indexer\n",
    "df.loc[df['age'] > 30, ['color', 'food']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful to break apart row and column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = df['age'] > 30\n",
    "cs = ['color', 'food']\n",
    "df.loc[rs, cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two common scenarios when assigning subsets of data\n",
    "1. You want to make an assignment to a particular subset of your DataFrame but want to keep doing analysis on the entire DataFrame\n",
    "1. You want to select a subset of data and store it as its own variable and modify that subset without modifying your original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/sample_data.csv', index_col=0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[['Aaron', 'Dean']]['color'] = 'PURPLE'\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idiomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ['Aaron', 'Dean']\n",
    "cs = 'color'\n",
    "df1.loc[rs, cs] = 'PURPLE'\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary of Scenario 1:\n",
    "* Use exactly one set of brackets to make the assignment\n",
    "* You know you've made a mistake when you see back to back brackets like this `][`\n",
    "* Separate row and column selection by a comma within the same set of brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scenario 2\n",
    "Scenario 2 exists when you take a subset of data and want to keep working with just that subset. You may not care at all about the original DataFrame, but you probably won't want to change its data.\n",
    "\n",
    "In this scenario, you will use the `copy` method to create a fresh independent copy of your subset and then make changes to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/sample_data.csv', index_col=0)\n",
    "food_score = df2[['food', 'score']]\n",
    "food_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria= food_score['food'].isin(['Steak', 'Lamb'])\n",
    "food_score.loc[criteria, 'score'] = 99\n",
    "food_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idiomatic\n",
    "Use the `copy` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_score = df[['food', 'score']].copy()\n",
    "\n",
    "criteria = food_score['food'].isin(['Steak', 'Lamb'])\n",
    "food_score.loc[criteria, 'score'] = 99\n",
    "food_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `.ix` is deprecated\n",
    "Remove every trace of it from your code. It is ambiguous. `.loc` and `.iloc` are explicit. Use them.\n",
    "\n",
    "### Very little reason to use `.at` and `.iat`\n",
    "These two indexers select a single cell from a DataFrame/Series. There is almost never going to be a case when they are necessary. They provide a small speed-up over `.loc` and `.iloc`, but if you really wanted to select data faster then you should drop down into NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `query` method\n",
    "It is more readable but does not work with columns with spaces. It also adds no additional functionality over normal boolean indexing, so why use it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('age > 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['age'] > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.rename(columns={'food': 'fave food'})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.query('fave food == \"Steak\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Arithmetic and Comparison Operators\n",
    "Use the arithmetic and comparison operators `+, -, *, /, <, >, <=, >=, ==, !=` over their counterpart methods `add, sub, mul, div, lt, gt, le, ge, eq, ne` unless you need to change the direction of an operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college = pd.read_csv('data/college.csv', index_col='instnm')\n",
    "pd.options.display.max_columns = 100\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_ugds = college.loc[:, 'ugds_white':'ugds_unkn']\n",
    "college_ugds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_ugds_mean = college_ugds.mean()\n",
    "race_ugds_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default is to align Series index with columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_ugds_mean_diff = college_ugds - race_ugds_mean\n",
    "college_ugds_mean_diff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_school_min = college_ugds.min(axis='columns')\n",
    "race_school_min.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blows up due to outer join of index\n",
    "college_ugds - race_school_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arithmetic and comparison **methods** default to `axis='columns'`. Almost all others default to axis='index'. We must use the `sub` method to change the direction of operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_ugds.sub(race_school_min, axis='index').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use DataFrame/Series methods\n",
    "A common mistake is to use a built-in core Python function instead of a DataFrame/Series method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugds = college['ugds'].dropna()\n",
    "ugds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ugds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugds.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No difference except when there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(college['ugds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college['ugds'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large performance difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugds1 = ugds.sample(n=10**6, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 sum(ugds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 ugds1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `apply` - the method that does nothing but is used the most often\n",
    "The `apply` method does basically nothing. It simply replaces a manual writing of a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_ugds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_ugds.apply(lambda x: x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 college_ugds.apply(lambda x: x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_ugds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 college_ugds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_ugds.apply(lambda x: x.max(), axis='columns').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_ugds.max(axis='columns').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huge time difference when doing `axis='columns'`\n",
    "A for-loop over the rows is a very slow operations. Avoid at all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 college_ugds.apply(lambda x: x.max(), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 college_ugds.max(axis='columns').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Acceptable usages of `apply`\n",
    "Only use `apply` when a built in pandas method does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_debt = college[['md_earn_wne_p10', 'grad_debt_mdn_supp']]\n",
    "earnings_debt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_debt.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_debt.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(earnings_debt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_debt.apply(pd.to_numeric, errors='coerce').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing complex objects inside DataFrames/Series\n",
    "Just because Pandas allows you to do something, does not mean it is a good idea. There is not good support for non-scalar values stored within cells of DataFrames/Series. Store multiple values in separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# never do this\n",
    "college_ugds.head(20).apply(lambda x: pd.Series({'max and min': [x.min(), x.max()]}), axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Know the three components of a groupby aggregation\n",
    "All groupby aggregations contain 3 components:\n",
    "* Grouping Columns - Unique combinations of these for independent groups\n",
    "* Aggregating Columns - The values in these columns will be aggregated to a single value\n",
    "* Aggregating functions - The type of aggregation to be used. Must output a single value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `groupby` syntax - standardize for readability\n",
    "There are a number of syntaxes that get used for the `groupby` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax that I use\n",
    "state_math_sat_max = college.groupby('stabbr') \\\n",
    "                            .agg({'satmtmid': 'max'})\n",
    "state_math_sat_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.groupby('stabbr')['satmtmid'].agg('max').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no reason to use the full word aggregate. Always use agg\n",
    "college.groupby('stabbr')['satmtmid'].aggregate('max').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.groupby('stabbr')['satmtmid'].max().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college[['stabbr', 'satmtmid']].groupby('stabbr').max().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Handling a MultiIndex - Usually after grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_stats = college.groupby(['stabbr', 'relaffil']) \\\n",
    "                   .agg({'ugds': ['min', 'max'], \n",
    "                        'satmtmid': ['median', 'max']})\n",
    "col_stats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I don't like MultiIndexes\n",
    "Personally, I find that MultiIndexes add no value to pandas. Selecting subsets of data from them is not obvious. Instead, renaming the columns by hand is not a bad strategy. We can also reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_stats.columns = ['min ugds', 'max ugds', 'median satmtmid', 'max satmtmid']\n",
    "col_stats = col_stats.reset_index()\n",
    "col_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Calling `apply` on a `groupby` object - be careful\n",
    "Using `apply` within a `groupby` can lead to disastrous performance. It is one of the slowest operations in all of pandas. \n",
    "\n",
    "### Finding the percentage of all undergraduates represented in the top 5 most populous colleges\n",
    "To accomplish this, we write a custom function to sort the values of each group from greatest to least. We then select the first 5 values with .iloc and sum them. We divide this sum by the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_perc(s):\n",
    "    s = s.sort_values(ascending=False)\n",
    "    top5_total = s.iloc[:5].sum()\n",
    "    total = s.sum()\n",
    "    return top5_total / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.groupby('stabbr').agg({'ugds': top5_perc}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run operations that are independent of the group outside of the custom function\n",
    "The best way to avoid giant performance leaks with groupby-apply is to run all operations that are independent of the group outside of the custom aggregation function. Here, we sort the entire DataFrame first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_perc_simple(s):\n",
    "    top5_total = s.iloc[:5].sum()\n",
    "    total = s.sum()\n",
    "    return top5_total / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.sort_values('ugds', ascending=False) \\\n",
    "       .groupby('stabbr').agg({'ugds': top5_perc_simple}).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 college.groupby('stabbr').agg({'ugds': top5_perc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 5 \n",
    "college.sort_values('ugds', ascending=False) \\\n",
    "       .groupby('stabbr').agg({'ugds': top5_perc_simple}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Power User Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_top5 = college.sort_values('ugds', ascending=False) \\\n",
    "                      .groupby('stabbr').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_total = college_top5.groupby('stabbr').agg({'ugds': 'sum'})\n",
    "top5_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = college.groupby('stabbr').agg({'ugds': 'sum'})\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(top5_total / total).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 5\n",
    "college_top5 = college.sort_values('ugds', ascending=False) \\\n",
    "                      .groupby('stabbr').head()\n",
    "top5_total = college_top5.groupby('stabbr').agg({'ugds': 'sum'})\n",
    "total = college.groupby('stabbr').agg({'ugds': 'sum'})\n",
    "top5_total / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `melt` vs `stack`\n",
    "These methods are virtually identical. I prefer `melt` as it avoids a multi-level index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('data/movie.csv')\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act1 = movie.melt(id_vars=['title'], \n",
    "                  value_vars=['actor1', 'actor2', 'actor3'], \n",
    "                  var_name='actor number',\n",
    "                  value_name='actor name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = movie.set_index('title')[['actor1', 'actor2', 'actor3']].stack()\n",
    "stacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.reset_index(name='actor name').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act1.pivot(index='title', columns='actor number', values='actor name').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `pivot_table` vs `groupby` then `unstack`\n",
    "`pivot_table` can directly create a pivot table. You can achieve the exact same result by grouping by multiple columns and then unstacking. I prefer the pivot table as it is clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = pd.read_csv('data/employee.csv')\n",
    "emp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.pivot_table(index='race', columns='gender', values='salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_gen_sal = emp.groupby(['race', 'gender']).agg({'salary': 'mean'})\n",
    "race_gen_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_gen_sal.unstack('gender')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
